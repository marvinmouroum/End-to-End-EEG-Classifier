{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL-CNN-LSTM.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "walmaCfwHT07",
        "colab_type": "code",
        "outputId": "348e3ef1-211c-4c2d-9a8b-67676ab1c8f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "!pip install pydrive"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pydrive in /usr/local/lib/python3.6/dist-packages (1.3.1)\n",
            "Requirement already satisfied: google-api-python-client>=1.2 in /usr/local/lib/python3.6/dist-packages (from pydrive) (1.6.7)\n",
            "Requirement already satisfied: oauth2client>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (4.1.3)\n",
            "Requirement already satisfied: PyYAML>=3.0 in /usr/local/lib/python3.6/dist-packages (from pydrive) (3.13)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (0.11.3)\n",
            "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (3.0.0)\n",
            "Requirement already satisfied: six<2dev,>=1.6.1 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.2->pydrive) (1.12.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.2.5)\n",
            "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client>=4.0.0->pydrive) (0.4.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZU-bZAV-HUrh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import roc_auc_score, precision_score, recall_score, accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "##### START OF ADDITION OF MY CODE\n",
        "\n",
        "import numpy as np\n",
        "import os.path\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import io\n",
        "from googleapiclient.http import MediaIoBaseDownload\n",
        "\n",
        "from scipy.io import loadmat\n",
        "from pathlib import Path\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io as sio\n",
        "import sys\n",
        "\n",
        "## PyTorch \n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "from torch import Tensor\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "\n",
        "import math #for calculus\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlJq32ymHUtn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "## END OF IMPORTS\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "#file_id = '1FrXb6rTyqpE5SmNtP8HhygDmFf9Lw896'\n",
        "file_id = '1al08tF3j-Z2-fowjPPNz1SrFgLVqywXG' ##1.mat\n",
        "#https://drive.google.com/open?id=1TqewoCjjRXZpEIxL_23ZQ8MP4L0RofZx\n",
        "file_id = '1TqewoCjjRXZpEIxL_23ZQ8MP4L0RofZx'\n",
        "#https://drive.google.com/open?id=1al08tF3j-Z2-fowjPPNz1SrFgLVqywXG\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('./train3.mat')\n",
        "#mat = loadmat('train3.mat')\n",
        "mat = sio.loadmat('train3.mat', squeeze_me=True, struct_as_record=False)\n",
        "data=[]\n",
        "\n",
        "## in class      \n",
        "device='cuda:0'\n",
        "learning_rate=0.01\n",
        "weight_decay=0.000001 \n",
        "momentum=0.9\n",
        "batch_size=200\n",
        "\n",
        "o=mat['o']\n",
        "\n",
        "data=mat['o'].data\n",
        "#print(data[200][21])\n",
        "labels=mat['o'].marker\n",
        "\n",
        "newlabels = np.zeros([data.shape[0],4])\n",
        "\n",
        "#print(newlabels.shape)\n",
        "#print(labels.shape)\n",
        "\n",
        "#print(np.amax(labels))\n",
        "\n",
        "found = np.zeros([1,])\n",
        "#print(found.shape)\n",
        "\n",
        "#clean the shit out of it\n",
        "while np.amax(labels) > 3:\n",
        "    ind = np.argmax(labels)\n",
        "    found = np.append(found,np.array([ind]), axis=0)\n",
        "    labels[ind] = 0\n",
        "    data[ind,:] = np.zeros([22,])\n",
        "    \n",
        "    \n",
        "\n",
        "\n",
        "#print(np.amax(labels))\n",
        "#print(found.shape)\n",
        "#print(found)\n",
        "\n",
        "inside = 0\n",
        "for y in labels:\n",
        "  if inside % 10000 == 0:\n",
        "    #print(inside)\n",
        "    newlabels[inside,y] = 1\n",
        "    inside += 1\n",
        "  \n",
        "#print(newlabels.shape)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhXrIcR8HUvp",
        "colab_type": "code",
        "outputId": "db82fc25-7b14-4b43-bf91-d70c3bfe1b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        }
      },
      "source": [
        "## video maker and data extractor\n",
        "\n",
        "pos=np.zeros((22,3), dtype=int)\n",
        "\n",
        "pos[0]=-2,10,0\n",
        "pos[1]=2,10,0\n",
        "pos[3]=-4,7,3\n",
        "pos[4]=4,7,3\n",
        "pos[5]=-5,0,4\n",
        "pos[6]=5,0,4\n",
        "pos[7]=-4,-7,3\n",
        "pos[8]=4,-7,3\n",
        "pos[9]=-2,-10,0\n",
        "pos[10]=2,-10,0\n",
        "pos[11]=-7,0,-5\n",
        "pos[12]=7,0,5\n",
        "pos[13]=-6,6,0\n",
        "pos[14]=6,6,0\n",
        "pos[15]=-7,0,0\n",
        "pos[16]=7,0,0\n",
        "pos[17]=-6,-6,0\n",
        "pos[18]=6,-6,0\n",
        "pos[19]=0,7,4\n",
        "pos[20]=0,0,6\n",
        "pos[21]=0,-7,4\n",
        "\n",
        "def make_3d_point(x,y,z,r,theta,phi):\n",
        "  return [\n",
        "      x + int(r * math.cos(theta)*math.sin(phi)),\n",
        "      y + int(r * math.sin(theta)*math.sin(phi)),\n",
        "      z + int(r * math.cos(phi))\n",
        "         ]\n",
        "\n",
        "def make_3d_image(image3d_data,shift):\n",
        "  \n",
        " # print(\"started a 3d image\")\n",
        "  \n",
        "  #creating the matrix\n",
        "  matrix = np.zeros([12,16,22]) # z,x,y\n",
        "  \n",
        "  #looping through data\n",
        "  for point in image3d_data:\n",
        "    \n",
        "    # creating the indice by shifting the coordinate system from the center to left corner\n",
        "    newpoint = [int(point[0]) + 7,int(point[1]) + 10,int(point[2]) + 5]\n",
        "    \n",
        "    if newpoint[0] >= matrix.shape[1] or newpoint[1] >= matrix.shape[2] or newpoint[2] >= matrix.shape[0] or newpoint[0] < 0 or newpoint[1] < 0 or newpoint[2] < 0:\n",
        "      print(\"did not add point\")\n",
        "      print(newpoint)\n",
        "      print(matrix.shape)\n",
        "      continue\n",
        "\n",
        "      \n",
        "    #the maximum value\n",
        "    cap = 400 + shift #based on the data (a peak - maximum value is equal or higher than 400)\n",
        "    \n",
        "    #for scaling the values between 0 and 255\n",
        "    scale = 255/cap\n",
        "    \n",
        "    #assigning the value\n",
        "    if int(point[3]) >= 0 and int(point[3]) <= cap:\n",
        "      if matrix[newpoint[2],newpoint[0],newpoint[1]] == 0 or matrix[newpoint[2],newpoint[0],newpoint[1]] < int(point[3]*scale):\n",
        "        matrix[newpoint[2],newpoint[0],newpoint[1]] = int(point[3]*scale)\n",
        "\n",
        "    elif int(point[3]) > cap:\n",
        "      if matrix[newpoint[2],newpoint[0],newpoint[1]] == 0 or matrix[newpoint[2],newpoint[0],newpoint[1]] < int(cap*scale):\n",
        "        matrix[newpoint[2],newpoint[0],newpoint[1]] = int(cap*scale)\n",
        "    else:\n",
        "      if matrix[newpoint[2],newpoint[0],newpoint[1]] < 0:\n",
        "        matrix[newpoint[2],newpoint[0],newpoint[1]] = 0\n",
        "    \n",
        "    #creating variables for creating a virtual sphere around poi\n",
        "    rho = [2,3] # distance (in pixels) that we are interpolating from poi\n",
        "    #theta  angle in radians    [0,2pi]\n",
        "    #phi    angle in radians    [0, pi]\n",
        "    \n",
        "    #creating new interpolated points\n",
        "    for r in rho:\n",
        "      for theta in range(0,360,45):\n",
        "        for phi in range(0,180,45):\n",
        "          p = make_3d_point(newpoint[0],newpoint[1],newpoint[2],r,math.radians(theta),math.radians(phi))\n",
        "          \n",
        "          #checking if its in bounds\n",
        "          if p[0] < matrix.shape[1] and p[1] < matrix.shape[2] and p[2] < matrix.shape[0] and p[0] >= 0 and p[1] >= 0 and p[2] >= 0:\n",
        "\n",
        "            \n",
        "            #assigning the value to the matrix, scaled down by distance\n",
        "            if int(point[3]) >= 0 and int(point[3]) <= cap:\n",
        "              if matrix[p[2],p[0],p[1]] == 0:\n",
        "                matrix[p[2],p[0],p[1]] = int(point[3]/r*scale)\n",
        "            elif int(point[3]) > cap:\n",
        "              if matrix[p[2],p[0],p[1]] == 0:\n",
        "                matrix[p[2],p[0],p[1]] = int(cap/r*scale)\n",
        "            else:\n",
        "              if matrix[p[2],p[0],p[1]] == 0:\n",
        "                matrix[p[2],p[0],p[1]] = 0\n",
        "            \n",
        "  return matrix\n",
        "\n",
        "\n",
        "start = 0\n",
        "end   = 3335\n",
        "#start = 0\n",
        "#end = 667000\n",
        "step = 1\n",
        "\n",
        "#shift the data because it has negative values\n",
        "shift_data = 300\n",
        "\\\n",
        "newdata = np.add(data,shift_data).reshape([22,data.shape[0]])\n",
        "\n",
        "video_stream = np.zeros([end-start,1,12,16,22])\n",
        "video_stream[0,0] = make_3d_image(np.hstack((pos,newdata[:,start].reshape([22,1]))),shift_data)\n",
        "\n",
        "print(np.hstack((pos,newdata[:,start].reshape([22,1]))))\n",
        "\n",
        "\n",
        "\"\"\"for t in range(start+step,end,step):\n",
        " \n",
        "  #create x,y,z,value for timestep t\n",
        "  data3d = np.hstack((pos,newdata[:,t].reshape([22,1])))\n",
        "  \n",
        "  #make image - with interpolated data for timestep t\n",
        "  result = make_3d_image(data3d,shift_data)\n",
        "  \n",
        "  #add image to video stream\n",
        "  video_stream[t-start,0] = result\n",
        "  \n",
        "  \n",
        "maxValue = np.amax(video_stream)\n",
        "minValue = np.amin(video_stream)\"\"\"\n",
        "\n",
        "#print(maxValue)\n",
        "#print(minValue)\n",
        "#print(video_stream[0,0,3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ -2.    10.     0.   300.  ]\n",
            " [  2.    10.     0.   302.51]\n",
            " [  0.     0.     0.   294.96]\n",
            " [ -4.     7.     3.   290.72]\n",
            " [  4.     7.     3.   323.97]\n",
            " [ -5.     0.     4.   292.55]\n",
            " [  5.     0.     4.   301.08]\n",
            " [ -4.    -7.     3.   300.43]\n",
            " [  4.    -7.     3.   300.  ]\n",
            " [ -2.   -10.     0.   306.18]\n",
            " [  2.   -10.     0.   306.36]\n",
            " [ -7.     0.    -5.   270.89]\n",
            " [  7.     0.     5.   303.68]\n",
            " [ -6.     6.     0.   290.32]\n",
            " [  6.     6.     0.   315.5 ]\n",
            " [ -7.     0.     0.   300.  ]\n",
            " [  7.     0.     0.   292.41]\n",
            " [ -6.    -6.     0.   299.85]\n",
            " [  6.    -6.     0.   291.02]\n",
            " [  0.     7.     4.   295.93]\n",
            " [  0.     0.     6.   283.45]\n",
            " [  0.    -7.     4.   300.77]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'for t in range(start+step,end,step):\\n \\n  #create x,y,z,value for timestep t\\n  data3d = np.hstack((pos,newdata[:,t].reshape([22,1])))\\n  \\n  #make image - with interpolated data for timestep t\\n  result = make_3d_image(data3d,shift_data)\\n  \\n  #add image to video stream\\n  video_stream[t-start,0] = result\\n  \\n  \\nmaxValue = np.amax(video_stream)\\nminValue = np.amin(video_stream)'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2j9nZCOzKGZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class eeg_CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(eeg_CNN, self).__init__()\n",
        "        self.T = 120\n",
        "        \n",
        "        self.conv1 = nn.Conv3d(1,5,2, stride=1,padding=(1,1,1),dilation=1)\n",
        "        self.batchnorm1 = nn.BatchNorm3d(5)\n",
        "        self.conv2 = nn.Conv3d(5,10,(2,3,2), stride=1,padding=(1,1,1),dilation=1)\n",
        "        self.batchnorm2 = nn.BatchNorm3d(10)\n",
        "        self.conv3 = nn.Conv3d(10,5,3, stride=1,dilation=1)\n",
        "        self.batchnorm3 = nn.BatchNorm3d(5)\n",
        "        self.conv4 = nn.Conv3d(5,5,(3,3,2), stride=1, dilation =1)\n",
        "        self.batchnorm4 = nn.BatchNorm3d(5)\n",
        "        self.conv5 = nn.Conv3d(5,5,(1,2,1), stride=1, dilation =1)\n",
        "        self.batchnorm5 = nn.BatchNorm3d(5)\n",
        "        self.pooling1 = nn.MaxPool3d((2,2,2), stride=1, dilation=1)\n",
        "        \n",
        "        #layer after max pool\n",
        "        self.conv6 = nn.Conv3d(5,5,3, stride=1,padding=(1,1,1),dilation=1)\n",
        "        self.batchnorm6 = nn.BatchNorm3d(5)\n",
        "        self.conv7 = nn.Conv3d(5,5,(3,3,2), stride=1,dilation=1)\n",
        "        self.batchnorm7 = nn.BatchNorm3d(5)\n",
        "        self.conv8 = nn.Conv3d(5,5,(1,2,1), stride=1,dilation=1)\n",
        "        self.batchnorm8 = nn.BatchNorm3d(5)\n",
        "        self.pooling2 = nn.MaxPool3d((3,3,2), stride=1, dilation=1)\n",
        "        \n",
        "        #Layer after next max pool \n",
        "        self.conv9 = nn.Conv3d(5,5,3, stride=1,padding=(1,1,1),dilation=1)\n",
        "        self.batchnorm9 = nn.BatchNorm3d(5)\n",
        "        self.conv10 = nn.Conv3d(5,5,(3,3,2), stride=1,dilation=1)\n",
        "        self.batchnorm10 = nn.BatchNorm3d(5)\n",
        "        self.conv11 = nn.Conv3d(5,1,(1,2,1), stride=1,dilation=1)\n",
        "        self.batchnorm11 = nn.BatchNorm3d(5)\n",
        "        self.pooling3 = nn.MaxPool3d((3,3,2), stride=1, dilation=1)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "      \n",
        "        # first set of CNNs and then a max pool\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.batchnorm1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.batchnorm2(x)\n",
        "        x = F.relu(self.conv3(x)) \n",
        "        x = self.batchnorm3(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.batchnorm4(x)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.batchnorm5(x)\n",
        "        x = self.pooling1(x)\n",
        "        \n",
        "        # second set\n",
        "        \n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = self.batchnorm6(x)\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = self.batchnorm7(x)\n",
        "        x = F.relu(self.conv8(x))\n",
        "        x = self.batchnorm9(x)\n",
        "        x = self.pooling2(x)\n",
        "        \n",
        "        # set 3  \n",
        "        \n",
        "        x = F.relu(self.conv9(x))\n",
        "        x = self.batchnorm10(x)\n",
        "        x = F.relu(self.conv10(x))\n",
        "        x = self.batchnorm11(x)\n",
        "        x = F.relu(self.conv11(x))\n",
        "        x = self.pooling3(x)\n",
        "        batch_size, timesteps, C, H, W = x.size()\n",
        "        c_in = x.view(batch_size * timesteps, C, H, W)\n",
        "        c_out = c_in[:,0,:,:]\n",
        "        return c_out\n",
        "      \n",
        "      \n",
        "      \n",
        "class eeg_LSTM(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(eeg_LSTM, self).__init__()\n",
        "        \n",
        "        #self.fc1 = nn.Linear(16 * 1 * 1, 10)\n",
        "        ## here is the start of the LSTM \n",
        "        self.rnn = nn.LSTM(16, 4, 2)\n",
        "        #self.fc1 = nn.Linear(4,4)\n",
        "\n",
        "    def forward(self, x):\n",
        "        C, H, W = x.size()\n",
        "        #print(\"shape in forward\",x.shape)\n",
        "        c_in = x.view(C, H, W)\n",
        "        print(\"shape in forward\",x.shape)\n",
        "        ##c_in = c_in[:,0,:,:]\n",
        "        r_out, _ = self.rnn(c_in)\n",
        "   \n",
        "        output = F.softmax(r_out) \n",
        "        return output\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gXFEMyYAHUyP",
        "colab_type": "code",
        "outputId": "b7ad69d5-2cec-4f4a-8755-e2a58f300063",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2333
        }
      },
      "source": [
        "\n",
        "\n",
        "class EEGNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(EEGNet, self).__init__()\n",
        "        self.T = 120\n",
        "        \n",
        "        self.conv1 = nn.Conv3d(1,5,2, stride=1,padding=(1,1,1),dilation=1)\n",
        "        self.batchnorm1 = nn.BatchNorm3d(5)\n",
        "        self.conv2 = nn.Conv3d(5,10,(2,3,2), stride=1,padding=(1,1,1),dilation=1)\n",
        "        self.batchnorm2 = nn.BatchNorm3d(10)\n",
        "        self.conv3 = nn.Conv3d(10,5,3, stride=1,dilation=1)\n",
        "        self.batchnorm3 = nn.BatchNorm3d(5)\n",
        "        self.conv4 = nn.Conv3d(5,5,(3,3,2), stride=1, dilation =1)\n",
        "        self.batchnorm4 = nn.BatchNorm3d(5)\n",
        "        self.conv5 = nn.Conv3d(5,5,(1,2,1), stride=1, dilation =1)\n",
        "        self.batchnorm5 = nn.BatchNorm3d(5)\n",
        "        self.pooling1 = nn.MaxPool3d((2,2,2), stride=1, dilation=1)\n",
        "        \n",
        "        #layer after max pool\n",
        "        self.conv6 = nn.Conv3d(5,5,3, stride=1,padding=(1,1,1),dilation=1)\n",
        "        self.batchnorm6 = nn.BatchNorm3d(5)\n",
        "        self.conv7 = nn.Conv3d(5,5,(3,3,2), stride=1,dilation=1)\n",
        "        self.batchnorm7 = nn.BatchNorm3d(5)\n",
        "        self.conv8 = nn.Conv3d(5,5,(1,2,1), stride=1,dilation=1)\n",
        "        self.batchnorm8 = nn.BatchNorm3d(5)\n",
        "        self.pooling2 = nn.MaxPool3d((3,3,2), stride=1, dilation=1)\n",
        "        \n",
        "        #Layer after next max pool \n",
        "        self.conv9 = nn.Conv3d(5,5,3, stride=1,padding=(1,1,1),dilation=1)\n",
        "        self.batchnorm9 = nn.BatchNorm3d(5)\n",
        "        self.conv10 = nn.Conv3d(5,5,(3,3,2), stride=1,dilation=1)\n",
        "        self.batchnorm10 = nn.BatchNorm3d(5)\n",
        "        self.conv11 = nn.Conv3d(5,1,(1,2,1), stride=1,dilation=1)\n",
        "        self.batchnorm11 = nn.BatchNorm3d(5)\n",
        "        self.pooling3 = nn.MaxPool3d((3,3,2), stride=1, dilation=1)\n",
        "        \n",
        "        #self.fc1 = nn.Linear(16 * 1 * 1, 10)\n",
        "        ## here is the start of the LSTM \n",
        "        self.rnn = nn.LSTM(16, 4, 2)\n",
        "        #self.fc1 = nn.Linear(4,4)\n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "      \n",
        "        # first set of CNNs and then a max pool\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.batchnorm1(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.batchnorm2(x)\n",
        "        x = F.relu(self.conv3(x)) \n",
        "        x = self.batchnorm3(x)\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = self.batchnorm4(x)\n",
        "        x = F.relu(self.conv5(x))\n",
        "        x = self.batchnorm5(x)\n",
        "        x = self.pooling1(x)\n",
        "        \n",
        "        # second set\n",
        "        \n",
        "        x = F.relu(self.conv6(x))\n",
        "        x = self.batchnorm6(x)\n",
        "        x = F.relu(self.conv7(x))\n",
        "        x = self.batchnorm7(x)\n",
        "        x = F.relu(self.conv8(x))\n",
        "        x = self.batchnorm9(x)\n",
        "        x = self.pooling2(x)\n",
        "        \n",
        "        # set 3  \n",
        "        \n",
        "        x = F.relu(self.conv9(x))\n",
        "        x = self.batchnorm10(x)\n",
        "        x = F.relu(self.conv10(x))\n",
        "        x = self.batchnorm11(x)\n",
        "        x = F.relu(self.conv11(x))\n",
        "        x = self.pooling3(x)\n",
        "        \n",
        " \n",
        "\n",
        "        #Start of LSTM\n",
        "        batch_size, timesteps, C, H, W = x.size()\n",
        "        c_in = x.view(batch_size * timesteps, C, H, W)\n",
        "        c_in = c_in[:,0,:,:]\n",
        "        #print(\"stsrting\")\n",
        "        #print(c_in.shape)\n",
        "        \n",
        "        r_out, _ = self.rnn(c_in)\n",
        "        #print(r_out.shape)\n",
        "        #print(\"endsing\")\n",
        "        \n",
        "        #t =  self.fc1(r_out)\n",
        "        #t = F.log_softmax(r_out, dim=0)\n",
        "        output = F.softmax(r_out)#, dim=0)\n",
        "        return output\n",
        "      \n",
        "## END OF ADDITION OF MY CODE\n",
        "      \n",
        "device='cuda:0'            \n",
        "net = EEGNet().to(device)\n",
        "preNet = eeg_CNN().to(device)\n",
        "lstm = eeg_LSTM().to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n",
        "#optimizer = torch.optim.SGD(net.parameters(), lr=0.08, momentum=0.9)\n",
        "loss = nn.CrossEntropyLoss()\n",
        "\n",
        "#X_train = video_stream.astype('float32') # our generated image\n",
        "#y_train = torch.from_numpy(labels.reshape(667000,1)[start:end])#()2668000,1\n",
        "\n",
        "y_train = torch.from_numpy(labels.reshape(667000,1))#()2668000,1\n",
        "\n",
        "\n",
        "batch_size = 115\n",
        "\n",
        "video_batch=29\n",
        "\n",
        "begin=0\n",
        "finish=3335\n",
        "\n",
        "step=0\n",
        "t=0\n",
        "print(begin, finish, step)\n",
        "#print(y_train.max())\n",
        "#for epoch in range(0,X_train.shape[0],batch_size):  # loop over the dataset multiple times ##\n",
        "for epoch in range(0,200):\n",
        "  print(\"\\nEpoch \", epoch)\n",
        "  running_loss = 0.0\n",
        "  \n",
        "  for t in range(begin,finish,1):\n",
        "    #create x,y,z,value for timestep t\n",
        "    data3d = np.hstack((pos,newdata[:,t].reshape([22,1])))\n",
        "    #make image - with interpolated data for timestep t\n",
        "    result = make_3d_image(data3d,shift_data)\n",
        "    #add image to video stream\n",
        "    video_stream[t-begin,0] = result\n",
        "  \n",
        "  \n",
        "  print(\"vid stream shape is \", video_stream.shape)\n",
        "  x_train = video_stream.astype('float32')# our generated image\n",
        "  y_train = torch.from_numpy(labels[begin:finish].reshape(finish-begin,1))#()2668000,1\n",
        "  begin = finish\n",
        "  step = 3335\n",
        "  t = t+step\n",
        "  finish = finish+step\n",
        "  print(\"next index begin is \", begin, \"finish is \", finish)\n",
        "  \n",
        "  print(\"Lets preprocess our batch of CNN images \")\n",
        "  vid_cnn = torch.zeros(video_batch,1,16)\n",
        "  vid_cnn.double()\n",
        "\n",
        "  \n",
        "  for i in range((len(x_train)//batch_size)-1):\n",
        "        s = i*1\n",
        "        e = i*1+1\n",
        "        preProcess = Variable(torch.tensor(x_train[s:e])).to(device)\n",
        "        out = preNet(preProcess)\n",
        "        #print(\"shape of out is \", out.shape)\n",
        "        vid_cnn[i] = out\n",
        "        \n",
        "  print(\"vi_cnn shape is \",vid_cnn.shape)\n",
        "  \n",
        "  print(\"Train on LSTM of processed CNN vids\")\n",
        "  for i in range((len(x_train)//batch_size)-1):   \n",
        "        optimizer.zero_grad()\n",
        "        s = i*batch_size\n",
        "        e = i*batch_size+batch_size\n",
        "        train = Variable(vid_cnn).to(device)\n",
        "        out = lstm(train)\n",
        "        last_output = out[-1]\n",
        "\n",
        "        target = Variable(torch.LongTensor([y_train[0:e-s].max()])).to(device)\n",
        "\n",
        "\n",
        "        err = loss(last_output, target)\n",
        "        err.backward()#retain_graph=True\n",
        "        optimizer.step()\n",
        "        if i % 6 == 0:\n",
        "          print(\"target \", target)\n",
        "          print(\"Loss is \",err , i, epoch)\n",
        "          print(\"Last output \",last_output[-1])\n",
        "  \n",
        "  \n",
        "  \n",
        "\"\"\"\n",
        "  for i in range((len(X_train)//batch_size)-1):   \n",
        "        optimizer.zero_grad()\n",
        "        s = i*batch_size\n",
        "        e = i*batch_size+batch_size\n",
        "        train = Variable(torch.tensor(X_train[s:e])).to(device)\n",
        "\n",
        "        out = net(train)\n",
        "        last_output = out[-1]\n",
        "\n",
        "        target = Variable(torch.LongTensor([y_train[0:e-s].max()])).to(device)\n",
        "\n",
        "        #print(target)\n",
        "        #print(last_output[-1])\n",
        "        err = loss(last_output, target)\n",
        "        err.backward()#retain_graph=True\n",
        "        optimizer.step()\n",
        "        if i % 6 == 0:\n",
        "          print(\"target \", target)\n",
        "          print(\"Loss is \",err , i, epoch)\n",
        "          print(\"Last output \",last_output[-1])\"\"\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 3335 0\n",
            "\n",
            "Epoch  0\n",
            "vid stream shape is  (3335, 1, 12, 16, 22)\n",
            "next index begin is  3335 finish is  6670\n",
            "Lets preprocess our batch of CNN images \n",
            "vi_cnn shape is  torch.Size([29, 1, 16])\n",
            "Train on LSTM of processed CNN vids\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3865, device='cuda:0', grad_fn=<NllLossBackward>) 0 0\n",
            "Last output  tensor([0.0347, 0.0351, 0.0352, 0.0345], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3865, device='cuda:0', grad_fn=<NllLossBackward>) 6 0\n",
            "Last output  tensor([0.0347, 0.0351, 0.0352, 0.0345], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:94: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3865, device='cuda:0', grad_fn=<NllLossBackward>) 12 0\n",
            "Last output  tensor([0.0347, 0.0351, 0.0352, 0.0345], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3865, device='cuda:0', grad_fn=<NllLossBackward>) 18 0\n",
            "Last output  tensor([0.0347, 0.0351, 0.0352, 0.0345], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3865, device='cuda:0', grad_fn=<NllLossBackward>) 24 0\n",
            "Last output  tensor([0.0347, 0.0351, 0.0352, 0.0345], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "\n",
            "Epoch  1\n",
            "vid stream shape is  (3335, 1, 12, 16, 22)\n",
            "next index begin is  6670 finish is  10005\n",
            "Lets preprocess our batch of CNN images \n",
            "vi_cnn shape is  torch.Size([29, 1, 16])\n",
            "Train on LSTM of processed CNN vids\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3865, device='cuda:0', grad_fn=<NllLossBackward>) 0 1\n",
            "Last output  tensor([0.0344, 0.0351, 0.0350, 0.0341], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3865, device='cuda:0', grad_fn=<NllLossBackward>) 6 1\n",
            "Last output  tensor([0.0344, 0.0351, 0.0350, 0.0341], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3865, device='cuda:0', grad_fn=<NllLossBackward>) 12 1\n",
            "Last output  tensor([0.0344, 0.0351, 0.0350, 0.0341], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3865, device='cuda:0', grad_fn=<NllLossBackward>) 18 1\n",
            "Last output  tensor([0.0344, 0.0351, 0.0350, 0.0341], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "target  tensor([0], device='cuda:0')\n",
            "Loss is  tensor(1.3865, device='cuda:0', grad_fn=<NllLossBackward>) 24 1\n",
            "Last output  tensor([0.0344, 0.0351, 0.0350, 0.0341], device='cuda:0',\n",
            "       grad_fn=<SelectBackward>)\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "shape in forward torch.Size([29, 1, 16])\n",
            "\n",
            "Epoch  2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-2f6387e22576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mdata3d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnewdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[0;31m#make image - with interpolated data for timestep t\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_3d_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata3d\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshift_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m     \u001b[0;31m#add image to video stream\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0mvideo_stream\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mbegin\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-055b12702eac>\u001b[0m in \u001b[0;36mmake_3d_image\u001b[0;34m(image3d_data, shift)\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mtheta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mphi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m180\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m           \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_3d_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnewpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnewpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradians\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mradians\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m           \u001b[0;31m#checking if its in bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-055b12702eac>\u001b[0m in \u001b[0;36mmake_3d_point\u001b[0;34m(x, y, z, r, theta, phi)\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m       \u001b[0mz\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m          ]\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjSLf3xUL1oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J0VCV89P8BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WCzqL7MHU05",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}